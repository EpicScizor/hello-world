{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow with GPU",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EpicScizor/hello-world/blob/master/TDT4171_Ex5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BlmQIFSLZDdc"
      },
      "cell_type": "markdown",
      "source": [
        "# Confirm TensorFlow can see the GPU\n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3IEVK-KFxi5Z",
        "outputId": "0940e8b1-5283-4b2d-e3e6-8853f3deb804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "QXRh0DPiZRyG"
      },
      "cell_type": "markdown",
      "source": [
        "# Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional neural network layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU\n",
        "to compare execution speed."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t9ALbbpmY9rm",
        "outputId": "3b4050cd-ab44-4a8a-d1a4-8d63be21546b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import graphviz\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import tree\n",
        "import tensorflow.keras as keras\n",
        "import pickle\n",
        "import time\n",
        "import traceback\n",
        "\n",
        "load_keras_model = False\n",
        "print(\"Defining functions\")\n",
        "\n",
        "def\tsk_readData():\n",
        "\tdata = pickle.load(open(\"sklearn-data.pickle\",\"rb\"))\n",
        "\t# Create a vectorizer with some parameters\n",
        "\tvectorizer = HashingVectorizer(stop_words = None, n_features = 2**20, binary = True)\n",
        "\tdata[\"x_train\"] = vectorizer.fit_transform(data.get(\"x_train\"))\n",
        "\tdata[\"x_test\"] = vectorizer.fit_transform(data.get(\"x_test\"))\n",
        "\treturn data\n",
        "\n",
        "def sk_classifier(obs,res,obs_test,res_test,method=\"Naive Bayes\"):\n",
        "\tif method == \"Naive Bayes\":\n",
        "\t\tclassifier = naive_bayes.BernoulliNB()\n",
        "\telif method == \"Tree\":\n",
        "\t\tclassifier = tree.DecisionTreeClassifier(max_depth = 10)\n",
        "\telse:\n",
        "\t\traise IOError(\"Error: Incorrect method\")\n",
        "\tclassifier.fit(X = obs, y = res)\n",
        "\tres_pred = classifier.predict(obs_test)\n",
        "\taccuracy = sklearn.metrics.accuracy_score(res_test, res_pred)\n",
        "\tprint(method,\"accuracy:\",accuracy)\n",
        "\treturn classifier\n",
        "\t\n",
        "def sk_main():\n",
        "\tprint(\"Importing sci-kit learn data\")\n",
        "\tdata = sk_readData()\n",
        "\tprint(\"Training Naive Bayes\")\n",
        "\tstart_bayes = time.time()\n",
        "\tmy_bayes = sk_classifier(data[\"x_train\"],\n",
        "\t\t\t\t\t\t\tdata[\"y_train\"],\n",
        "\t\t\t\t\t\t\tdata[\"x_test\"],\n",
        "\t\t\t\t\t\t\tdata[\"y_test\"],\n",
        "\t\t\t\t\t\t\tmethod=\"Naive Bayes\")\n",
        "\tend_bayes = time.time()\n",
        "\tprint(\"Naive Bayes time:\",end_bayes-start_bayes)\n",
        "\tprint(\"Training Decision Tree\")\n",
        "\tmy_tree = sk_classifier(data[\"x_train\"],\n",
        "\t\t\t\t\t\t\tdata[\"y_train\"],\n",
        "\t\t\t\t\t\t\tdata[\"x_test\"],\n",
        "\t\t\t\t\t\t\tdata[\"y_test\"],\n",
        "\t\t\t\t\t\t\tmethod=\"Tree\")\n",
        "\tend_tree = time.time()\n",
        "\tprint(\"Tree time:\",end_tree-end_bayes)\n",
        "\treturn [my_bayes,my_tree]\n",
        "\n",
        "def k_readData(maxlen = 200):\n",
        "\tdata = pickle.load(open(\"keras-data.pickle\",\"rb\"))\n",
        "\tdata[\"x_train\"] = keras.preprocessing.sequence.pad_sequences(data[\"x_train\"],maxlen=maxlen,padding='post',truncating='post')\n",
        "\tdata[\"y_train\"] = np.stack((np.asarray(data[\"y_train\"]),1-np.asarray(data[\"y_train\"])),axis=1)\n",
        "\tdata[\"x_test\"] = keras.preprocessing.sequence.pad_sequences(data[\"x_test\"],maxlen=maxlen,padding='post',truncating='post')\n",
        "\tdata[\"y_test\"] = np.stack((np.asarray(data[\"y_test\"]),1-np.asarray(data[\"y_test\"])),axis=1)\n",
        "\treturn data\n",
        "\n",
        "def inspectData():\n",
        "\tdata = pickle.load(open(\"keras-data.pickle\",\"rb\"))\n",
        "\txlen = np.array(range(0,np.shape(data[\"x_train\"])[0]))\n",
        "\tk = 0\n",
        "\tfor i in data[\"x_train\"]:\n",
        "\t\tc[k] = len(i)\n",
        "\t\tk = k+1\n",
        "\tplt.hist(c,bins = 50)\n",
        "\tplt.show()\n",
        "\t\n",
        "def defineModel(input_dim = 1000,embed_dim = 32,input_length = 256,hidden_nodes = 32):\t\n",
        "\tmodel = keras.Sequential()\n",
        "\tmodel.add(keras.layers.Embedding(input_dim = input_dim,\n",
        "\t\t\t\t\t\t\t\t\toutput_dim = embed_dim,\n",
        "\t\t\t\t\t\t\t\t\tinput_length = input_length))\n",
        "\tmodel.add(keras.layers.LSTM(hidden_nodes,dropout=0.2,recurrent_dropout=0.2))\n",
        "\tmodel.add(keras.layers.Dense(2,activation='sigmoid'))\n",
        "\tmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\tprint(model.summary())\n",
        "\treturn model\n",
        "\n",
        "def evaluateKeras(data,model,batch_size = 32,epochs = 10):\n",
        "\tearly_stopping_monitor = keras.callbacks.EarlyStopping(patience=2)\n",
        "\tmodel.fit(data[\"x_train\"],\n",
        "\t\t\tdata[\"y_train\"],\n",
        "\t\t\tbatch_size = batch_size,\n",
        "\t\t\tepochs = epochs,\n",
        "\t\t\tcallbacks = [early_stopping_monitor])\n",
        "\taccuracy = model.evaluate(data[\"x_test\"],data[\"y_test\"])\n",
        "\tprint(\"Accuracy:\",accuracy)\n",
        "\treturn model\n",
        "\t\n",
        "def k_main():\n",
        "\t## Hyperparameters\n",
        "\tembed_dim = 32 # dimension of embedded dense vector\n",
        "\thidden_nodes = 32 # amount of hidden nodes in LSTM\n",
        "\tbatch_size = 32\n",
        "\tepochs = 10\n",
        "\tinput_length = 256\n",
        "\t\n",
        "\t## Read data from file\n",
        "\tprint(\"Importing keras-data\")\n",
        "\tdata = k_readData(maxlen = input_length)\n",
        "\n",
        "\tvocab_size = data[\"vocab_size\"]\n",
        "\t\n",
        "\tif load_keras_model:\n",
        "\t\tprint(\"Loading keras model from file\")\n",
        "\t\tmodel = load_model('saved_keras_model.h5')\n",
        "\telse:\n",
        "\t\tprint(\"Defining keras model\")\n",
        "\t\tmodel = defineModel(input_dim = vocab_size,embed_dim = embed_dim,input_length = input_length)\n",
        "\t\tprint(\"Training keras model\")\n",
        "\t\tstart = time.time()\n",
        "\t\tmodel = evaluateKeras(data,model,batch_size,epochs)\n",
        "\t\tend = time.time()\n",
        "\t\tprint(\"Recurrent Neural Network time:\",end-start)\n",
        "\t\tmodel.save('saved_keras_model.h5')\n",
        "\treturn model\n",
        "\n",
        "print(\"Executing main scripts\")\n",
        "#sk_main()\n",
        "k_main()\n",
        "input(\"Press enter to close\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defining functions\n",
            "Executing main scripts\n",
            "Importing keras-data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f189ad8a85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Executing main scripts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m#sk_main()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mk_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Press enter to close\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5f189ad8a85d>\u001b[0m in \u001b[0;36mk_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m## Read data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Importing keras-data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_readData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vocab_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-5f189ad8a85d>\u001b[0m in \u001b[0;36mk_readData\u001b[0;34m(maxlen)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mk_readData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras-data.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_train\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'keras-data.pickle'"
          ]
        }
      ]
    }
  ]
}